# CLIP å…³é”®å¸§æ£€æµ‹ - å¿«é€Ÿå…¥é—¨

## ä»€ä¹ˆæ˜¯ CLIP å…³é”®å¸§æ£€æµ‹ï¼Ÿ

CLIP (Contrastive Language-Image Pre-training) æ˜¯ OpenAI å¼€å‘çš„è§†è§‰-è¯­è¨€æ¨¡å‹ã€‚ç”¨äºå…³é”®å¸§æ£€æµ‹æ—¶ï¼Œå®ƒèƒ½ï¼š

- ğŸ§  **ç†è§£è¯­ä¹‰**ï¼šä¸åªçœ‹åƒç´ ï¼Œè¿˜ç†è§£å†…å®¹
- ğŸ¯ **ç²¾å‡†åˆ‡åˆ†**ï¼šåŸºäºåœºæ™¯å†…å®¹è€Œéè§†è§‰å˜åŒ–
- ğŸ’ª **é²æ£’æ€§å¼º**ï¼šå¯¹å…‰ç…§ã€è§’åº¦ã€ç¼©æ”¾å˜åŒ–ä¸æ•æ„Ÿ

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
cd backend
uv sync  # å·²åŒ…å«æ‰€æœ‰ä¾èµ–
```

### 2. åŸºç¡€ä½¿ç”¨

```python
import asyncio
from master_clash.video_analysis import CLIPKeyframeDetector

async def main():
    # åˆ›å»ºæ£€æµ‹å™¨
    detector = CLIPKeyframeDetector(
        model_name="openai/clip-vit-base-patch32",
        distance_threshold=0.3,
        frame_sample_rate=3,
        device="auto"  # è‡ªåŠ¨é€‰æ‹© GPU/CPU
    )

    # æ£€æµ‹å…³é”®å¸§
    keyframes = await detector.detect_keyframes_async(
        video_path="your_video.mp4",
        save_images=True,
        save_curve=True  # ä¿å­˜è·ç¦»æ›²çº¿å›¾
    )

    # æŸ¥çœ‹ç»“æœ
    for kf in keyframes:
        print(f"æ—¶é—´: {kf.timestamp:.2f}s, å¸§å·: {kf.frame_number}")

asyncio.run(main())
```

### 3. ä¾¿æ·å‡½æ•°

```python
from master_clash.video_analysis.keyframes_clip import (
    detect_with_clip_fast,      # å¿«é€Ÿæ¨¡å¼
    detect_with_clip_accurate,  # ç²¾ç¡®æ¨¡å¼
    detect_with_clip_balanced   # å¹³è¡¡æ¨¡å¼ï¼ˆæ¨èï¼‰
)

# ä¸€è¡Œä»£ç æå®š
keyframes = detect_with_clip_balanced("video.mp4")
```

## å·¥ä½œåŸç†

### 1. æå–è¯­ä¹‰ç‰¹å¾

```python
è§†é¢‘å¸§ â†’ CLIP â†’ 512ç»´åµŒå…¥å‘é‡

å¸§1: [äººç‰©, å®¤å†…, å®¶å…·] â†’ [0.23, -0.45, 0.12, ...]
å¸§2: [äººç‰©, å®¤å†…, å®¶å…·] â†’ [0.25, -0.43, 0.14, ...]  # ç›¸ä¼¼
å¸§3: [æˆ·å¤–, è¡—é“, å»ºç­‘] â†’ [0.85, 0.32, -0.67, ...]  # ä¸åŒ
```

### 2. è®¡ç®—è·ç¦»æ›²çº¿

```python
ä½™å¼¦è·ç¦» = 1 - cosine_similarity(embedding1, embedding2)

å¸§1â†’å¸§2: è·ç¦» = 0.05 (ç›¸ä¼¼)
å¸§2â†’å¸§3: è·ç¦» = 0.65 (ä¸åŒ) â† å³°å€¼ï¼Œæ£€æµ‹ä¸ºåœºæ™¯åˆ‡æ¢
```

### 3. å³°å€¼æ£€æµ‹

```
è·ç¦»æ›²çº¿ï¼š
 |     *
 |    * *              *
 |   *   *            * *
 |  *     *          *   *
 | *       *    *   *     *
 |*         ****  **       **
 +-------------------------> æ—¶é—´
           â†‘    â†‘
         åœºæ™¯   åœºæ™¯
         åˆ‡æ¢   åˆ‡æ¢
```

## å‚æ•°è°ƒä¼˜

### é‡‡æ ·ç‡ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰

```python
# å¿«é€Ÿæ¨¡å¼ - é•¿è§†é¢‘ï¼ˆ>30åˆ†é’Ÿï¼‰
frame_sample_rate=5  # æ¯5å¸§é‡‡æ ·ä¸€æ¬¡
# å¤„ç†é€Ÿåº¦: çº¦5å€æå‡
# å‡†ç¡®åº¦: è½»å¾®ä¸‹é™

# æ ‡å‡†æ¨¡å¼ - ä¸€èˆ¬è§†é¢‘
frame_sample_rate=3  # æ¨è
# å¹³è¡¡é€Ÿåº¦å’Œå‡†ç¡®åº¦

# ç²¾ç¡®æ¨¡å¼ - çŸ­è§†é¢‘æˆ–å…³é”®å†…å®¹
frame_sample_rate=1  # æ¯å¸§éƒ½åˆ†æ
# æœ€é«˜å‡†ç¡®åº¦ï¼Œé€Ÿåº¦è¾ƒæ…¢
```

### é˜ˆå€¼è°ƒæ•´

```python
# æ•æ„Ÿæ¨¡å¼ - æ£€æµ‹æ›´å¤šåœºæ™¯
CLIPKeyframeDetector(
    distance_threshold=0.2,   # ä½é˜ˆå€¼
    peak_prominence=0.05      # ä½æ˜¾è‘—æ€§
)
# ç»“æœ: æ›´å¤šå…³é”®å¸§

# ä¿å®ˆæ¨¡å¼ - åªæ£€æµ‹æ˜æ˜¾å˜åŒ–
CLIPKeyframeDetector(
    distance_threshold=0.4,   # é«˜é˜ˆå€¼
    peak_prominence=0.2       # é«˜æ˜¾è‘—æ€§
)
# ç»“æœ: æ›´å°‘ä½†æ›´æ˜¾è‘—çš„å…³é”®å¸§
```

### æ¨¡å‹é€‰æ‹©

```python
# åŸºç¡€æ¨¡å‹ï¼ˆæ¨èï¼‰
model_name="openai/clip-vit-base-patch32"
# å¤§å°: ~600MB
# é€Ÿåº¦: å¿«
# å‡†ç¡®åº¦: é«˜ï¼ˆè¶³å¤Ÿç”¨ï¼‰

# å¤§æ¨¡å‹ï¼ˆç ”ç©¶çº§ï¼‰
model_name="openai/clip-vit-large-patch14"
# å¤§å°: ~900MB
# é€Ÿåº¦: è¾ƒæ…¢
# å‡†ç¡®åº¦: æœ€é«˜
```

## å®é™…æ¡ˆä¾‹

### æ¡ˆä¾‹ 1: ç”µå½±åˆ†æ

```python
detector = CLIPKeyframeDetector(
    model_name="openai/clip-vit-base-patch32",
    distance_threshold=0.3,
    peak_prominence=0.15,  # è¾ƒé«˜æ˜¾è‘—æ€§
    frame_sample_rate=2,
    device="cuda"
)

keyframes = await detector.detect_keyframes_async(
    "movie.mp4",
    save_curve=True,
    max_keyframes=100
)
```

**ç»“æœ**:
- å‡†ç¡®è¯†åˆ«åœºæ™¯åˆ‡æ¢ï¼ˆå®¤å†…â†’æˆ·å¤–ã€ç™½å¤©â†’å¤œæ™šï¼‰
- å¿½ç•¥ç›¸æœºåˆ‡æ¢ï¼ˆåŒä¸€åœºæ™¯çš„ä¸åŒè§’åº¦ï¼‰
- æ•æ‰æƒ…èŠ‚è½¬æŠ˜ç‚¹

### æ¡ˆä¾‹ 2: Vlog åˆ†å‰²

```python
from master_clash.video_analysis.keyframes_clip import detect_with_clip_balanced

keyframes = detect_with_clip_balanced(
    "travel_vlog.mp4",
    save_images=True
)

# è‡ªåŠ¨åˆ†å‰²ï¼šæµ·æ»© â†’ é¤å… â†’ é…’åº— â†’ æ™¯ç‚¹
```

### æ¡ˆä¾‹ 3: æ•™è‚²è§†é¢‘

```python
detector = CLIPKeyframeDetector(
    distance_threshold=0.25,  # æ•æ„Ÿæ¨¡å¼
    frame_sample_rate=2,      # è¾ƒé«˜ç²¾åº¦
)

keyframes = await detector.detect_keyframes_async(
    "lecture.mp4",
    save_images=True
)

# æ•æ‰ PPT åˆ‡æ¢å’Œæ¼”ç¤ºå†…å®¹å˜åŒ–
```

## è¾“å‡ºç¤ºä¾‹

### 1. å…³é”®å¸§åˆ—è¡¨

```python
[
    Keyframe(
        timestamp=0.0,
        frame_number=0,
        image_path="keyframes/keyframe_000000_0.00s.jpg",
        score=1.0
    ),
    Keyframe(
        timestamp=15.5,
        frame_number=465,
        image_path="keyframes/keyframe_000465_15.50s.jpg",
        score=1.0
    ),
    ...
]
```

### 2. è·ç¦»æ›²çº¿å›¾

è®¾ç½® `save_curve=True` ä¼šç”Ÿæˆ `distance_curve.png`ï¼š

```
è¾“å‡ºç›®å½•/
â”œâ”€â”€ keyframes/
â”‚   â”œâ”€â”€ keyframe_000000_0.00s.jpg
â”‚   â”œâ”€â”€ keyframe_000465_15.50s.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ distance_curve.png  â† å¯è§†åŒ–è·ç¦»æ›²çº¿
```

## æ€§èƒ½ä¼˜åŒ–æŠ€å·§

### GPU åŠ é€Ÿ

```python
# è‡ªåŠ¨æ£€æµ‹ï¼ˆæ¨èï¼‰
detector = CLIPKeyframeDetector(device="auto")

# æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ GPU
import torch
print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
print(f"å½“å‰è®¾å¤‡: {detector.device}")
```

**æ€§èƒ½å¯¹æ¯”**:
- GPU (NVIDIA RTX 3080): ~0.5ç§’/å¸§
- CPU (Intel i9): ~2ç§’/å¸§

### å†…å­˜ä¼˜åŒ–

```python
# å¢åŠ é‡‡æ ·ç‡å‡å°‘å†…å­˜å ç”¨
detector = CLIPKeyframeDetector(
    frame_sample_rate=5,  # å†…å­˜å ç”¨å‡å°‘ 5 å€
)

# å¤„ç†è¶…é•¿è§†é¢‘æ—¶åˆ†æ®µå¤„ç†
# ï¼ˆåœ¨ç¼–æ’å™¨ä¸­è‡ªåŠ¨å¤„ç†ï¼‰
```

### æ‰¹å¤„ç†

```python
# å¤„ç†å¤šä¸ªè§†é¢‘
videos = ["video1.mp4", "video2.mp4", "video3.mp4"]

for video in videos:
    keyframes = detect_with_clip_balanced(video)
    print(f"{video}: {len(keyframes)} å…³é”®å¸§")
```

## æ•…éšœæ’é™¤

### é—®é¢˜ 1: æ¨¡å‹ä¸‹è½½å¤±è´¥

```bash
# æ‰‹åŠ¨è®¾ç½® HuggingFace ç¼“å­˜ç›®å½•
export HF_HOME=/path/to/cache

# æˆ–ä½¿ç”¨é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com
```

### é—®é¢˜ 2: GPU å†…å­˜ä¸è¶³

```python
# æ–¹æ¡ˆ1: å¢åŠ é‡‡æ ·ç‡
frame_sample_rate=5

# æ–¹æ¡ˆ2: ä½¿ç”¨ CPU
device="cpu"

# æ–¹æ¡ˆ3: ä½¿ç”¨å°æ¨¡å‹
model_name="openai/clip-vit-base-patch32"
```

### é—®é¢˜ 3: æ£€æµ‹åˆ°å¤ªå¤šå…³é”®å¸§

```python
# å¢åŠ é˜ˆå€¼å’Œæ˜¾è‘—æ€§
detector = CLIPKeyframeDetector(
    distance_threshold=0.4,   # ä» 0.3 æé«˜åˆ° 0.4
    peak_prominence=0.2,      # ä» 0.1 æé«˜åˆ° 0.2
    min_interval=2.0          # æœ€å°é—´éš” 2 ç§’
)
```

### é—®é¢˜ 4: æ£€æµ‹åˆ°å¤ªå°‘å…³é”®å¸§

```python
# é™ä½é˜ˆå€¼
detector = CLIPKeyframeDetector(
    distance_threshold=0.2,   # ä» 0.3 é™ä½åˆ° 0.2
    peak_prominence=0.05,     # ä» 0.1 é™ä½åˆ° 0.05
)
```

## å¯¹æ¯”å…¶ä»–æ–¹æ³•

| æ–¹æ³• | åŒä¸€åœºæ™¯ä¸åŒè§’åº¦ | ä¸åŒåœºæ™¯ç›¸ä¼¼å…‰ç…§ | æ¸å˜åœºæ™¯ |
|------|------------------|------------------|----------|
| ç°åº¦ç›´æ–¹å›¾ | âŒ è¯¯åˆ¤ | âŒ æ¼åˆ¤ | âŒ è¯¯åˆ¤ |
| PySceneDetect | âš ï¸ å¯èƒ½è¯¯åˆ¤ | âœ… æ­£ç¡® | âœ… æ­£ç¡® |
| **CLIP** | âœ… **æ­£ç¡®** | âœ… **æ­£ç¡®** | âœ… **æ­£ç¡®** |

## æ€»ç»“

**CLIP å…³é”®å¸§æ£€æµ‹æœ€é€‚åˆ**:
- âœ… å¤æ‚è§†é¢‘ï¼ˆç”µå½±ã€çºªå½•ç‰‡ã€Vlogï¼‰
- âœ… éœ€è¦ç†è§£å†…å®¹è€Œéä»…è§†è§‰
- âœ… å…‰ç…§ã€è§’åº¦å˜åŒ–é¢‘ç¹çš„è§†é¢‘
- âœ… ç ”ç©¶çº§åº”ç”¨

**æƒè¡¡è€ƒè™‘**:
- âš–ï¸ éœ€è¦ä¸‹è½½è¾ƒå¤§æ¨¡å‹ï¼ˆé¦–æ¬¡ï¼‰
- âš–ï¸ GPU åŠ é€Ÿæ•ˆæœæ˜¾è‘—
- âš–ï¸ æ¯”ä¼ ç»Ÿæ–¹æ³•æ…¢ï¼Œä½†å‡†ç¡®åº¦é«˜å¾—å¤š

**å¿«é€Ÿå†³ç­–**:
```python
# æœ‰ GPU + å¤æ‚è§†é¢‘ â†’ CLIP
detector = CLIPKeyframeDetector(device="cuda")

# æ—  GPU / ç®€å•è§†é¢‘ â†’ PySceneDetect
from master_clash.video_analysis import PySceneDetectKeyframeDetector
detector = PySceneDetectKeyframeDetector()

# å¿«é€Ÿæµ‹è¯• â†’ åŸºç¡€ç‰ˆ
from master_clash.video_analysis import KeyframeDetector
detector = KeyframeDetector()
```

æŸ¥çœ‹ [KEYFRAME_ALGORITHMS.md](src/master_clash/video_analysis/KEYFRAME_ALGORITHMS.md) äº†è§£æ‰€æœ‰ç®—æ³•çš„è¯¦ç»†å¯¹æ¯”ï¼
