{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c6eb5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Models: Text='gemini-3-pro-preview', Image='gemini-3-pro-image-preview'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# --- Configuration ---\n",
    "# ensure GOOGLE_API_KEY is set in your environment\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBFhyItl61CrSDyQEXIqQzwNOBwO8Pgv_o\"\n",
    "\n",
    "# MODEL CONFIGURATION\n",
    "# Strict adherence to user requested models\n",
    "TEXT_MODEL_NAME = \"gemini-3-pro-preview\"\n",
    "IMAGE_MODEL_NAME = \"gemini-3-pro-image-preview\"\n",
    "\n",
    "\n",
    "print(f\"Using Models: Text='{TEXT_MODEL_NAME}', Image='{IMAGE_MODEL_NAME}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ba9affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mimetypes\n",
    "import base64\n",
    "\n",
    "class Camera(BaseModel):\n",
    "    shot_size: str = Field(description=\"e.g., 'Medium Shot', 'Close-up'\")\n",
    "    angle: str = Field(description=\"e.g., 'Eye-level', 'High angle'\")\n",
    "    movement: str = Field(description=\"e.g., 'Tracking', 'Static', 'Pan'\")\n",
    "\n",
    "class VisualSpec(BaseModel):\n",
    "    camera: Camera\n",
    "    blocking: str = Field(description=\"Spatial layout and positioning\")\n",
    "    lighting_atmosphere: str = Field(description=\"Lighting and mood description\")\n",
    "\n",
    "class Performance(BaseModel):\n",
    "    emotional_context: str = Field(description=\"Internal feeling, e.g., 'Curiosity mixed with fear'\")\n",
    "    visible_acting: str = Field(description=\"External action, e.g., 'Slowly reaching out hand'\")\n",
    "\n",
    "class Audio(BaseModel):\n",
    "    dialogue: str = Field(default=\"\", description=\"Spoken dialogue\")\n",
    "    sfx: str = Field(default=\"\", description=\"Sound effects\")\n",
    "\n",
    "class Shot(BaseModel):\n",
    "    shot_id: int = Field(description=\"Shot number/ID\")\n",
    "    scene_id: str = Field(description=\"Reference to location ID\")\n",
    "    char_ids: List[str] = Field(default_factory=list, description=\"List of character IDs in this shot\")\n",
    "    duration_sec: int = Field(description=\"Duration in seconds\")\n",
    "    narrative_beat: str = Field(description=\"Which part of the story outline\")\n",
    "    visual_spec: VisualSpec\n",
    "    performance: Performance\n",
    "    audio: Audio\n",
    "\n",
    "class Character(BaseModel):\n",
    "    id: str = Field(description=\"Unique character ID, e.g., 'char_1'\")\n",
    "    name: str\n",
    "    visual_anchor: str = Field(description=\"Fixed visual features for consistency\")\n",
    "\n",
    "class Location(BaseModel):\n",
    "    id: str = Field(description=\"Unique location ID, e.g., 'loc_1'\")\n",
    "    name: str\n",
    "    environment_anchor: str = Field(description=\"Fixed environment details for consistency\")\n",
    "\n",
    "class Concept(BaseModel):\n",
    "    story_outline: str = Field(description=\"Colloquial summary of the entire plot\")\n",
    "    genre: str\n",
    "    global_aesthetic: str = Field(description=\"Art style, lighting, and mood keywords\")\n",
    "\n",
    "class Assets(BaseModel):\n",
    "    characters: List[Character]\n",
    "    locations: List[Location]\n",
    "\n",
    "class ScriptOutput(BaseModel):\n",
    "    step_1_concept: Concept\n",
    "    step_2_assets: Assets\n",
    "    step_3_sequence: List[Shot]\n",
    "\n",
    "# --- Tools ---\n",
    "\n",
    "def save_binary_file(file_name, data):\n",
    "    \"\"\"Helper function to save binary image data\"\"\"\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        f.write(data)\n",
    "    print(f\"âœ… File saved to: {file_name}\")\n",
    "\n",
    "def image_to_base64(image_path: str) -> str:\n",
    "    \"\"\"Convert image file to base64 string\"\"\"\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "@tool\n",
    "def generate_image(\n",
    "    prompt: str, \n",
    "    filename: str, \n",
    "    reference_images_base64: Optional[List[Dict[str, str]]] = None,\n",
    "    system_instruction: str = \"\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generates an image using the gemini-3-pro-image-preview model based on the prompt.\n",
    "    Supports multiple reference images for consistency.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The detailed image generation prompt.\n",
    "        filename: The filename to save the image as (e.g., 'char_noah.png').\n",
    "        reference_images_base64: Optional list of dicts with 'data' (base64 string) and 'mime_type' (e.g., 'image/png').\n",
    "                                 Example: [{\"data\": \"base64string...\", \"mime_type\": \"image/png\"}]\n",
    "        system_instruction: Optional system instruction for consistent style.\n",
    "    \"\"\"\n",
    "    from google import genai\n",
    "    from google.genai import types\n",
    "    \n",
    "    print(f\"\\nðŸŽ¨ [Generating Image] '{filename}'\")\n",
    "    print(f\"   Prompt: {prompt[:100]}...\")\n",
    "    if reference_images_base64:\n",
    "        print(f\"   Reference Images: {len(reference_images_base64)} image(s)\")\n",
    "    \n",
    "    client = genai.Client(\n",
    "        api_key=os.environ.get(\"GEMINI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    model = IMAGE_MODEL_NAME\n",
    "    \n",
    "    # Build parts list with text prompt and optional reference images\n",
    "    parts = []\n",
    "    \n",
    "    # Add reference images first if provided\n",
    "    if reference_images_base64:\n",
    "        for ref_img in reference_images_base64:\n",
    "            image_data = base64.b64decode(ref_img['data'])\n",
    "            mime_type = ref_img.get('mime_type', 'image/png')\n",
    "            parts.append(types.Part.from_bytes(data=image_data, mime_type=mime_type))\n",
    "    \n",
    "    # Add text prompt\n",
    "    parts.append(types.Part.from_text(text=prompt))\n",
    "    \n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=parts,\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        response_modalities=[\n",
    "            \"IMAGE\",\n",
    "            \"TEXT\",\n",
    "        ],\n",
    "        image_config=types.ImageConfig(\n",
    "            image_size=\"1K\",\n",
    "        ),\n",
    "        tools=[types.Tool(googleSearch=types.GoogleSearch())],\n",
    "        system_instruction=[\n",
    "            types.Part.from_text(text=system_instruction),\n",
    "        ] if system_instruction else None,\n",
    "    )\n",
    "\n",
    "    save_dir = \"production_assets\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    file_index = 0\n",
    "    saved_files = []\n",
    "    \n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=generate_content_config,\n",
    "    ):\n",
    "        if (\n",
    "            chunk.candidates is None\n",
    "            or chunk.candidates[0].content is None\n",
    "            or chunk.candidates[0].content.parts is None\n",
    "        ):\n",
    "            continue\n",
    "            \n",
    "        if chunk.candidates[0].content.parts[0].inline_data and chunk.candidates[0].content.parts[0].inline_data.data:\n",
    "            inline_data = chunk.candidates[0].content.parts[0].inline_data\n",
    "            data_buffer = inline_data.data\n",
    "            file_extension = mimetypes.guess_extension(inline_data.mime_type)\n",
    "            \n",
    "            # Use provided filename or generate one\n",
    "            if file_index == 0 and filename:\n",
    "                base_name = os.path.splitext(filename)[0]\n",
    "                file_path = os.path.join(save_dir, f\"{base_name}{file_extension}\")\n",
    "            else:\n",
    "                file_path = os.path.join(save_dir, f\"{filename}_{file_index}{file_extension}\")\n",
    "                \n",
    "            save_binary_file(file_path, data_buffer)\n",
    "            saved_files.append(file_path)\n",
    "            file_index += 1\n",
    "        else:\n",
    "            if chunk.text:\n",
    "                print(f\"   Model response: {chunk.text}\")\n",
    "    \n",
    "    if saved_files:\n",
    "        return f\"Image(s) saved: {', '.join(saved_files)}\"\n",
    "    else:\n",
    "        return \"No images were generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ym207tw2jmj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Nano Banana Pro functions loaded!\n"
     ]
    }
   ],
   "source": [
    "# %% Nano Banana Pro Image Generation\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Nano Banana Pro API Configuration\n",
    "NANO_BANANA_API_KEY = os.environ.get(\"NANO_BANANA_API_KEY\", \"6094ea861eb8183c5aa3bce1ffe981da\")\n",
    "NANO_BANANA_BASE_URL = \"https://api.kie.ai/api/v1/jobs\"\n",
    "\n",
    "def create_nano_banana_task(\n",
    "    prompt: str,\n",
    "    image_inputs: Optional[List[str]] = None,\n",
    "    aspect_ratio: str = \"1:1\",\n",
    "    resolution: str = \"1K\",\n",
    "    output_format: str = \"png\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Create a Nano Banana Pro image generation task.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Text description of the image (max 5000 chars)\n",
    "        image_inputs: Optional list of base64-encoded images (max 8 images, 30MB each)\n",
    "        aspect_ratio: \"1:1\", \"2:3\", \"3:2\", \"3:4\", \"4:3\", \"4:5\", \"5:4\", \"9:16\", \"16:9\", \"21:9\"\n",
    "        resolution: \"1K\", \"2K\", \"4K\"\n",
    "        output_format: \"png\", \"jpg\"\n",
    "    \n",
    "    Returns:\n",
    "        taskId: Task ID for querying results\n",
    "    \"\"\"\n",
    "    url = f\"{NANO_BANANA_BASE_URL}/createTask\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {NANO_BANANA_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"nano-banana-pro\",\n",
    "        \"input\": {\n",
    "            \"prompt\": prompt,\n",
    "            \"image_input\": image_inputs or [],\n",
    "            \"aspect_ratio\": aspect_ratio,\n",
    "            \"resolution\": resolution,\n",
    "            \"output_format\": output_format\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    result = response.json()\n",
    "    if result[\"code\"] == 200:\n",
    "        return result[\"data\"][\"taskId\"]\n",
    "    else:\n",
    "        raise Exception(f\"Task creation failed: {result['msg']}\")\n",
    "\n",
    "\n",
    "def query_nano_banana_task(task_id: str, max_retries: int = 180, retry_interval: int = 2) -> dict:\n",
    "    \"\"\"\n",
    "    Query Nano Banana Pro task status and results.\n",
    "    \n",
    "    Args:\n",
    "        task_id: Task ID from create_nano_banana_task\n",
    "        max_retries: Maximum number of polling attempts\n",
    "        retry_interval: Seconds to wait between polls\n",
    "    \n",
    "    Returns:\n",
    "        Task result data including resultUrls\n",
    "    \"\"\"\n",
    "    url = f\"{NANO_BANANA_BASE_URL}/recordInfo\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {NANO_BANANA_API_KEY}\"\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        response = requests.get(url, params={\"taskId\": task_id}, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        result = response.json()\n",
    "        if result[\"code\"] != 200:\n",
    "            raise Exception(f\"Query failed: {result['msg']}\")\n",
    "        \n",
    "        data = result[\"data\"]\n",
    "        state = data[\"state\"]\n",
    "        \n",
    "        if state == \"success\":\n",
    "            result_json = json.loads(data[\"resultJson\"])\n",
    "            return {\n",
    "                \"state\": state,\n",
    "                \"resultUrls\": result_json.get(\"resultUrls\", []),\n",
    "                \"costTime\": data.get(\"costTime\"),\n",
    "                \"taskId\": task_id\n",
    "            }\n",
    "        elif state == \"fail\":\n",
    "            raise Exception(f\"Task failed: {data['failMsg']} (code: {data['failCode']})\")\n",
    "        elif state == \"waiting\":\n",
    "            print(f\"   â³ Waiting... (attempt {attempt + 1}/{max_retries})\")\n",
    "            time.sleep(retry_interval)\n",
    "        else:\n",
    "            raise Exception(f\"Unknown state: {state}\")\n",
    "    \n",
    "    raise Exception(f\"Task timeout after {max_retries * retry_interval} seconds\")\n",
    "\n",
    "\n",
    "def generate_image_nano(\n",
    "    prompt: str,\n",
    "    filename: str,\n",
    "    reference_images_base64: Optional[List[Dict[str, str]]] = None,\n",
    "    aspect_ratio: str = \"1:1\",\n",
    "    resolution: str = \"1K\",\n",
    "    output_format: str = \"png\",\n",
    "    system_instruction: str = \"\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate image using Nano Banana Pro API with optional reference images.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Text description of the image\n",
    "        filename: Output filename (without extension)\n",
    "        reference_images_base64: Optional list of dicts with 'data' (base64) and 'mime_type'\n",
    "        aspect_ratio: Image aspect ratio\n",
    "        resolution: Image resolution\n",
    "        output_format: Output format (png or jpg)\n",
    "        system_instruction: Additional style instruction (will be prepended to prompt)\n",
    "    \n",
    "    Returns:\n",
    "        Success message with saved file path\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸŽ¨ [Generating Image with Nano Banana] '{filename}'\")\n",
    "    print(f\"   Prompt: {prompt[:100]}...\")\n",
    "    \n",
    "    # Combine system instruction with prompt\n",
    "    full_prompt = prompt\n",
    "    if system_instruction:\n",
    "        full_prompt = f\"Style: {system_instruction}\\n\\n{prompt}\"\n",
    "        print(f\"   System Instruction: {system_instruction}\")\n",
    "    \n",
    "    # Prepare image inputs (extract base64 data only)\n",
    "    image_inputs = []\n",
    "    if reference_images_base64:\n",
    "        print(f\"   Reference Images: {len(reference_images_base64)} image(s)\")\n",
    "        for ref_img in reference_images_base64:\n",
    "            image_inputs.append(ref_img['data'])\n",
    "    \n",
    "    # Create task\n",
    "    print(\"   ðŸ“¤ Creating task...\")\n",
    "    task_id = create_nano_banana_task(\n",
    "        prompt=full_prompt,\n",
    "        image_inputs=image_inputs,\n",
    "        aspect_ratio=aspect_ratio,\n",
    "        resolution=resolution,\n",
    "        output_format=output_format\n",
    "    )\n",
    "    print(f\"   âœ… Task created: {task_id}\")\n",
    "    \n",
    "    # Query results\n",
    "    print(\"   â³ Waiting for results...\")\n",
    "    result = query_nano_banana_task(task_id)\n",
    "    \n",
    "    # Download and save images\n",
    "    save_dir = \"production_assets\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    saved_files = []\n",
    "    \n",
    "    for idx, image_url in enumerate(result[\"resultUrls\"]):\n",
    "        print(f\"   ðŸ“¥ Downloading image {idx + 1}...\")\n",
    "        image_response = requests.get(image_url)\n",
    "        image_response.raise_for_status()\n",
    "        \n",
    "        # Determine file extension\n",
    "        ext = output_format if output_format in ['png', 'jpg'] else 'png'\n",
    "        if idx == 0:\n",
    "            file_path = os.path.join(save_dir, f\"{filename}.{ext}\")\n",
    "        else:\n",
    "            file_path = os.path.join(save_dir, f\"{filename}_{idx}.{ext}\")\n",
    "        \n",
    "        # Save file\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            f.write(image_response.content)\n",
    "        \n",
    "        saved_files.append(file_path)\n",
    "        print(f\"   âœ… Saved: {file_path}\")\n",
    "    \n",
    "    print(f\"   â±ï¸  Generation took {result['costTime']}ms\")\n",
    "    \n",
    "    if saved_files:\n",
    "        return f\"Image(s) saved: {', '.join(saved_files)}\"\n",
    "    else:\n",
    "        return \"No images were generated\"\n",
    "\n",
    "\n",
    "print(\"âœ… Nano Banana Pro functions loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7966ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [Agent 1] Script Generation Agent\n",
    "# This agent takes raw input and structures it.\n",
    "\n",
    "from google.genai import client\n",
    "\n",
    "\n",
    "def load_input_data(source: str):\n",
    "    \"\"\"Helper to load text or CSV data.\"\"\"\n",
    "    if source.endswith(\".csv\") and os.path.exists(source):\n",
    "        df = pd.read_csv(source)\n",
    "        return df.to_markdown(index=False)\n",
    "    return source\n",
    "\n",
    "# INPUT YOUR IDEA OR FILE PATH HERE\n",
    "user_input_source = \"A sci-fi short about a robot finding a flower in a wasteland.\"\n",
    "# user_input_source = \"å›žå¿†ç½è„šæœ¬.csv\" \n",
    "\n",
    "print(\"--- Running Agent 1: Script Generation ---\")\n",
    "\n",
    "input_content = load_input_data(user_input_source)\n",
    "\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# We use the structured output capability of the model directly for the best result\n",
    "# equivalent to a specialized agent for data extraction.\n",
    "script_llm = ChatGoogleGenerativeAI(model=TEXT_MODEL_NAME, temperature=0.7,\n",
    "    client = genai.Client(\n",
    "        api_key=os.environ.get(\"GEMINI_API_KEY\"),\n",
    "    ))\n",
    "structured_script_llm = script_llm.with_structured_output(ScriptOutput)\n",
    "\n",
    "system_prompt_1 = \"\"\"\n",
    "# Role\n",
    "You are an expert Director & Screenwriter Agent.\n",
    "Your process is: **Concept -> Assets -> Execution**.\n",
    "\n",
    "# Task\n",
    "Convert user input into a structured **Video Production Blueprint (JSON)**.\n",
    "\n",
    "# Execution Flow (Strict Order)\n",
    "1.  **Story Outline**: First, write a concise, colloquial summary of the entire plot. Expand on the user's input to ensure a beginning, middle, and end.\n",
    "2.  **Assets Definition**: Based on the outline, define the consistent characters and locations (`visual_anchor`).\n",
    "3.  **Shot Breakdown**: Finally, breakdown the outline into specific shots with detailed visual and acting instructions.\n",
    "\n",
    "# JSON Output Schema\n",
    "Output ONLY a valid JSON object matching this structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"step_1_concept\": {\n",
    "    \"story_outline\": \"String (Simple, colloquial summary of the plot. e.g., 'A boy finds a robot in the rain, they become friends, but the police chase them away.').\",\n",
    "    \"genre\": \"String\",\n",
    "    \"global_aesthetic\": \"String (Art style, lighting, and mood keywords)\"\n",
    "  },\n",
    "  \"step_2_assets\": {\n",
    "    \"characters\": [\n",
    "      {\n",
    "        \"id\": \"char_1\",\n",
    "        \"name\": \"String\",\n",
    "        \"visual_anchor\": \"String (Fixed visual features. e.g., 'Teenage boy, yellow raincoat, messy hair')\"\n",
    "      }\n",
    "    ],\n",
    "    \"locations\": [\n",
    "      {\n",
    "        \"id\": \"loc_1\",\n",
    "        \"name\": \"String\",\n",
    "        \"environment_anchor\": \"String (Fixed environment details. e.g., 'Cyberpunk alleyway, neon signs, wet pavement')\"\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"step_3_sequence\": [\n",
    "    {\n",
    "      \"shot_id\": 1,\n",
    "      \"scene_id\": \"loc_1\",\n",
    "      \"char_ids\": [\"char_1\"],\n",
    "      \"duration_sec\": 4,\n",
    "      \"narrative_beat\": \"String (Which part of the outline is this?)\",\n",
    "      \"visual_spec\": {\n",
    "        \"camera\": {\n",
    "          \"shot_size\": \"String (e.g., 'Medium Shot')\",\n",
    "          \"angle\": \"String (e.g., 'Eye-level')\",\n",
    "          \"movement\": \"String (e.g., 'Tracking')\"\n",
    "        },\n",
    "        \"blocking\": \"String (Where are they standing? Spatial layout.)\",\n",
    "        \"lighting_atmosphere\": \"String\"\n",
    "      },\n",
    "      \"performance\": {\n",
    "        \"emotional_context\": \"String (The internal feeling, e.g., 'Curiosity mixed with fear')\",\n",
    "        \"visible_acting\": \"String (The external action, e.g., 'Slowly reaching out hand, eyes wide, body tense')\"\n",
    "      },\n",
    "      \"audio\": {\n",
    "        \"dialogue\": \"String\",\n",
    "        \"sfx\": \"String\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Execute Agent 1\n",
    "script_result = structured_script_llm.invoke([\n",
    "    SystemMessage(content=system_prompt_1),\n",
    "    HumanMessage(content=input_content)\n",
    "])\n",
    "\n",
    "# Display Result\n",
    "print(f\"\\nðŸ“– Story: {script_result.step_1_concept.story_outline[:100]}...\")\n",
    "print(f\"ðŸŽ¨ Aesthetic: {script_result.step_1_concept.global_aesthetic}\")\n",
    "print(f\"ðŸŽ­ Genre: {script_result.step_1_concept.genre}\")\n",
    "print(f\"ðŸ‘¥ Characters: {len(script_result.step_2_assets.characters)}\")\n",
    "print(f\"ðŸ“ Locations: {len(script_result.step_2_assets.locations)}\")\n",
    "print(f\"ðŸŽ¬ Shots: {len(script_result.step_3_sequence)}\")\n",
    "\n",
    "from langchain_core.load import dumps\n",
    "print(json.dumps(script_result.model_dump(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70e14d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [Agent 2] Asset Generation Agent\n",
    "# This agent generates consistent character and location reference images\n",
    "\n",
    "print(\"\\n--- Running Agent 2: Asset Generation ---\")\n",
    "\n",
    "# Store generated asset images with their base64 data for later reference\n",
    "asset_images = {}\n",
    "\n",
    "# System instruction for consistent style across all assets\n",
    "global_style_instruction = script_result.step_1_concept.global_aesthetic\n",
    "\n",
    "# Generate Character Reference Images\n",
    "print(\"\\nðŸŽ­ Generating Character Reference Images...\")\n",
    "for char in script_result.step_2_assets.characters:\n",
    "    char_prompt = f\"\"\"\n",
    "Character Design Sheet:\n",
    "Name: {char.name}\n",
    "Visual Description: {char.visual_anchor}\n",
    "\n",
    "Style: {global_style_instruction}\n",
    "\n",
    "Create a detailed character reference image showing the character from multiple angles (front, side, back view).\n",
    "Include close-up details of important features.\n",
    "This will be used as a visual anchor for consistent character appearance throughout the production.\n",
    "\"\"\"\n",
    "    \n",
    "    filename = f\"{char.id}_reference\"\n",
    "    result = generate_image.invoke({\n",
    "        \"prompt\": char_prompt,\n",
    "        \"filename\": filename,\n",
    "        \"system_instruction\": global_style_instruction\n",
    "    })\n",
    "    \n",
    "    # Store the path for later use\n",
    "    if \"saved\" in result.lower():\n",
    "        file_path = result.split(\": \")[1] if \": \" in result else None\n",
    "        if file_path:\n",
    "            # Convert to base64 for future reference\n",
    "            asset_images[char.id] = {\n",
    "                \"path\": file_path,\n",
    "                \"base64\": image_to_base64(file_path),\n",
    "                \"mime_type\": \"image/png\"\n",
    "            }\n",
    "    print(f\"   âœ… {char.name}: {result}\")\n",
    "\n",
    "# Generate Location Reference Images\n",
    "print(\"\\nðŸ“ Generating Location Reference Images...\")\n",
    "for loc in script_result.step_2_assets.locations:\n",
    "    loc_prompt = f\"\"\"\n",
    "Environment/Location Design:\n",
    "Name: {loc.name}\n",
    "Visual Description: {loc.environment_anchor}\n",
    "\n",
    "Style: {global_style_instruction}\n",
    "\n",
    "Create a detailed environment/location concept art showing the setting from multiple perspectives.\n",
    "Include atmospheric details, lighting, and mood.\n",
    "This will be used as a visual anchor for consistent location appearance throughout the production.\n",
    "\"\"\"\n",
    "    \n",
    "    filename = f\"{loc.id}_reference\"\n",
    "    result = generate_image.invoke({\n",
    "        \"prompt\": loc_prompt,\n",
    "        \"filename\": filename,\n",
    "        \"system_instruction\": global_style_instruction\n",
    "    })\n",
    "    \n",
    "    # Store the path for later use\n",
    "    if \"saved\" in result.lower():\n",
    "        file_path = result.split(\": \")[1] if \": \" in result else None\n",
    "        if file_path:\n",
    "            asset_images[loc.id] = {\n",
    "                \"path\": file_path,\n",
    "                \"base64\": image_to_base64(file_path),\n",
    "                \"mime_type\": \"image/png\"\n",
    "            }\n",
    "    print(f\"   âœ… {loc.name}: {result}\")\n",
    "\n",
    "print(f\"\\nâœ… Asset Generation Complete! Generated {len(asset_images)} reference images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a547c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [Agent 3] Shot Generation Agent\n",
    "# This agent generates individual shot images based on the script and asset references\n",
    "\n",
    "print(\"\\n--- Running Agent 3: Shot Generation ---\")\n",
    "\n",
    "shot_images = []\n",
    "\n",
    "for shot in script_result.step_3_sequence:\n",
    "    print(f\"\\nðŸŽ¬ Generating Shot {shot.shot_id}...\")\n",
    "    print(f\"   Narrative Beat: {shot.narrative_beat}\")\n",
    "    \n",
    "    # Build reference images list (characters + location)\n",
    "    reference_images = []\n",
    "    \n",
    "    # Add character references\n",
    "    for char_id in shot.char_ids:\n",
    "        if char_id in asset_images:\n",
    "            reference_images.append({\n",
    "                \"data\": asset_images[char_id][\"base64\"],\n",
    "                \"mime_type\": asset_images[char_id][\"mime_type\"]\n",
    "            })\n",
    "    \n",
    "    # Add location reference\n",
    "    if shot.scene_id in asset_images:\n",
    "        reference_images.append({\n",
    "            \"data\": asset_images[shot.scene_id][\"base64\"],\n",
    "            \"mime_type\": asset_images[shot.scene_id][\"mime_type\"]\n",
    "        })\n",
    "    \n",
    "    # Build detailed shot prompt\n",
    "    shot_prompt = f\"\"\"\n",
    "Shot #{shot.shot_id}\n",
    "Duration: {shot.duration_sec} seconds\n",
    "\n",
    "NARRATIVE CONTEXT:\n",
    "{shot.narrative_beat}\n",
    "\n",
    "CAMERA SETUP:\n",
    "- Shot Size: {shot.visual_spec.camera.shot_size}\n",
    "- Camera Angle: {shot.visual_spec.camera.angle}\n",
    "- Camera Movement: {shot.visual_spec.camera.movement}\n",
    "\n",
    "BLOCKING & COMPOSITION:\n",
    "{shot.visual_spec.blocking}\n",
    "\n",
    "LIGHTING & ATMOSPHERE:\n",
    "{shot.visual_spec.lighting_atmosphere}\n",
    "\n",
    "PERFORMANCE & ACTION:\n",
    "- Emotional Context: {shot.performance.emotional_context}\n",
    "- Visible Acting: {shot.performance.visible_acting}\n",
    "\n",
    "AUDIO (for context):\n",
    "- Dialogue: {shot.audio.dialogue}\n",
    "- SFX: {shot.audio.sfx}\n",
    "\n",
    "Generate a single keyframe that captures this exact moment.\n",
    "Use the reference images provided to maintain character and location consistency.\n",
    "Focus on cinematography, composition, and the emotional beat of the scene.\n",
    "\"\"\"\n",
    "    \n",
    "    filename = f\"shot_{shot.shot_id:03d}\"\n",
    "    result = generate_image.invoke({\n",
    "        \"prompt\": shot_prompt,\n",
    "        \"filename\": filename,\n",
    "        \"reference_images_base64\": reference_images if reference_images else None,\n",
    "        \"system_instruction\": global_style_instruction\n",
    "    })\n",
    "    \n",
    "    shot_images.append({\n",
    "        \"shot_id\": shot.shot_id,\n",
    "        \"result\": result\n",
    "    })\n",
    "    \n",
    "    print(f\"   âœ… {result}\")\n",
    "\n",
    "print(f\"\\nðŸŽ‰ Shot Generation Complete! Generated {len(shot_images)} shots.\")\n",
    "print(f\"\\nðŸ“ All assets saved to: production_assets/\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PRODUCTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ðŸ“– Title: {script_result.step_1_concept.story_outline[:80]}...\")\n",
    "print(f\"ðŸŽ¨ Style: {script_result.step_1_concept.global_aesthetic}\")\n",
    "print(f\"ðŸ‘¥ Characters Generated: {len([k for k in asset_images.keys() if k.startswith('char')])}\")\n",
    "print(f\"ðŸ“ Locations Generated: {len([k for k in asset_images.keys() if k.startswith('loc')])}\")\n",
    "print(f\"ðŸŽ¬ Total Shots: {len(shot_images)}\")\n",
    "print(f\"â±ï¸  Estimated Duration: {sum(shot.duration_sec for shot in script_result.step_3_sequence)} seconds\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rglg8q122vc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ§ª TESTING IMAGE GENERATION FUNCTION\n",
      "============================================================\n",
      "\n",
      "ðŸ“¸ Test 1: Generating initial image (no references)...\n",
      "\n",
      "ðŸŽ¨ [Generating Image] 'test_robot_original'\n",
      "   Prompt: \n",
      "A cute robot character standing in a field of flowers.\n",
      "The robot has a round body, large expressive...\n"
     ]
    },
    {
     "ename": "RemoteProtocolError",
     "evalue": "Server disconnected without sending a response.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteProtocolError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:101\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:231\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    230\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mServer disconnected without sending a response.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteProtocolError(msg)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mreceive_data(data)\n",
      "\u001b[0;31mRemoteProtocolError\u001b[0m: Server disconnected without sending a response.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRemoteProtocolError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 110\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ“¸ Test 1: Generating initial image (no references)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m test_prompt_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124mA cute robot character standing in a field of flowers.\u001b[39m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124mThe robot has a round body, large expressive eyes, and is painted in bright blue and yellow colors.\u001b[39m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124mStyle: Pixar-style 3D animation, vibrant colors, soft lighting.\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m--> 110\u001b[0m result_1 \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_image_test\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_prompt_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_robot_original\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem_instruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPixar-style 3D animation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    114\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult 1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult_1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# Extract the file path from result\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 61\u001b[0m, in \u001b[0;36mgenerate_image_test\u001b[0;34m(prompt, filename, reference_images_base64, system_instruction)\u001b[0m\n\u001b[1;32m     58\u001b[0m file_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     59\u001b[0m saved_files \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 61\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerate_content_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcandidates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcandidates\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcandidates\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mcontinue\u001b[39;49;00m\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/google/genai/models.py:5395\u001b[0m, in \u001b[0;36mModels.generate_content_stream\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   5389\u001b[0m function_map \u001b[38;5;241m=\u001b[39m _extra_utils\u001b[38;5;241m.\u001b[39mget_function_map(parsed_config)\n\u001b[1;32m   5391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   5392\u001b[0m   \u001b[38;5;66;03m# First request gets a function call.\u001b[39;00m\n\u001b[1;32m   5393\u001b[0m   \u001b[38;5;66;03m# Then get function response parts.\u001b[39;00m\n\u001b[1;32m   5394\u001b[0m   \u001b[38;5;66;03m# Yield chunks only if there's no function response parts.\u001b[39;00m\n\u001b[0;32m-> 5395\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   5396\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunction_map\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   5397\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_extra_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend_chunk_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/google/genai/models.py:4089\u001b[0m, in \u001b[0;36mModels._generate_content_stream\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   4081\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[1;32m   4082\u001b[0m     config, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshould_return_http_response\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4083\u001b[0m ):\n\u001b[1;32m   4084\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4085\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccessing the raw HTTP response is not supported in streaming\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   4086\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m methods.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   4087\u001b[0m   )\n\u001b[0;32m-> 4089\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_streamed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4090\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   4093\u001b[0m \u001b[43m  \u001b[49m\u001b[43mresponse_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4095\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvertexai\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1405\u001b[0m, in \u001b[0;36mBaseApiClient.request_streamed\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrequest_streamed\u001b[39m(\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1396\u001b[0m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1399\u001b[0m     http_options: Optional[HttpOptionsOrDict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1400\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Generator[SdkHttpResponse, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m   1401\u001b[0m   http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[1;32m   1402\u001b[0m       http_method, path, request_dict, http_options\n\u001b[1;32m   1403\u001b[0m   )\n\u001b[0;32m-> 1405\u001b[0m   session_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1406\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m session_response\u001b[38;5;241m.\u001b[39msegments():\n\u001b[1;32m   1407\u001b[0m     chunk_dump \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(chunk)\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1224\u001b[0m, in \u001b[0;36mBaseApiClient._request\u001b[0;34m(self, http_request, http_options, stream)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     retry \u001b[38;5;241m=\u001b[39m tenacity\u001b[38;5;241m.\u001b[39mRetrying(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mretry_kwargs)\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[0;32m-> 1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/tenacity/__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/tenacity/__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/tenacity/__init__.py:420\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    418\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/tenacity/__init__.py:187\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 187\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/tenacity/__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 480\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    482\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1188\u001b[0m, in \u001b[0;36mBaseApiClient._request_once\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m   1181\u001b[0m   httpx_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpx_client\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m   1182\u001b[0m       method\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m   1183\u001b[0m       url\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1186\u001b[0m       timeout\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[1;32m   1187\u001b[0m   )\n\u001b[0;32m-> 1188\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_httpx_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttpx_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1189\u001b[0m   errors\u001b[38;5;241m.\u001b[39mAPIError\u001b[38;5;241m.\u001b[39mraise_for_response(response)\n\u001b[1;32m   1190\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[1;32m   1191\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[1;32m   1192\u001b[0m   )\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:249\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhttpcore\u001b[39;00m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m    250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    156\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:118\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    117\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mRemoteProtocolError\u001b[0m: Server disconnected without sending a response."
     ]
    }
   ],
   "source": [
    "# %% [TEST] Test Image Generation Function\n",
    "# Test 1: Generate an initial image without references\n",
    "# Test 2: Use that image as reference to generate a variant\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "def generate_image_test(prompt, filename, reference_images_base64=None, system_instruction=\"\"):\n",
    "    \"\"\"Test version of generate_image without @tool decorator\"\"\"\n",
    "    print(f\"\\nðŸŽ¨ [Generating Image] '{filename}'\")\n",
    "    print(f\"   Prompt: {prompt[:100]}...\")\n",
    "    if reference_images_base64:\n",
    "        print(f\"   Reference Images: {len(reference_images_base64)} image(s)\")\n",
    "    \n",
    "    client = genai.Client(\n",
    "        api_key=os.environ.get(\"GEMINI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    model = IMAGE_MODEL_NAME\n",
    "    \n",
    "    # Build parts list with text prompt and optional reference images\n",
    "    parts = []\n",
    "    \n",
    "    # Add reference images first if provided\n",
    "    if reference_images_base64:\n",
    "        for ref_img in reference_images_base64:\n",
    "            image_data = base64.b64decode(ref_img['data'])\n",
    "            mime_type = ref_img.get('mime_type', 'image/png')\n",
    "            parts.append(types.Part.from_bytes(data=image_data, mime_type=mime_type))\n",
    "    \n",
    "    # Add text prompt\n",
    "    parts.append(types.Part.from_text(text=prompt))\n",
    "    \n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=parts,\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        response_modalities=[\n",
    "            \"IMAGE\",\n",
    "            \"TEXT\",\n",
    "        ],\n",
    "        image_config=types.ImageConfig(\n",
    "            image_size=\"1K\",\n",
    "        ),\n",
    "        tools=[types.Tool(googleSearch=types.GoogleSearch())],\n",
    "        system_instruction=[\n",
    "            types.Part.from_text(text=system_instruction),\n",
    "        ] if system_instruction else None,\n",
    "    )\n",
    "\n",
    "    save_dir = \"production_assets\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    file_index = 0\n",
    "    saved_files = []\n",
    "    \n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=generate_content_config,\n",
    "    ):\n",
    "        if (\n",
    "            chunk.candidates is None\n",
    "            or chunk.candidates[0].content is None\n",
    "            or chunk.candidates[0].content.parts is None\n",
    "        ):\n",
    "            continue\n",
    "            \n",
    "        if chunk.candidates[0].content.parts[0].inline_data and chunk.candidates[0].content.parts[0].inline_data.data:\n",
    "            inline_data = chunk.candidates[0].content.parts[0].inline_data\n",
    "            data_buffer = inline_data.data\n",
    "            file_extension = mimetypes.guess_extension(inline_data.mime_type)\n",
    "            \n",
    "            # Use provided filename or generate one\n",
    "            if file_index == 0 and filename:\n",
    "                base_name = os.path.splitext(filename)[0]\n",
    "                file_path = os.path.join(save_dir, f\"{base_name}{file_extension}\")\n",
    "            else:\n",
    "                file_path = os.path.join(save_dir, f\"{filename}_{file_index}{file_extension}\")\n",
    "                \n",
    "            save_binary_file(file_path, data_buffer)\n",
    "            saved_files.append(file_path)\n",
    "            file_index += 1\n",
    "        else:\n",
    "            if chunk.text:\n",
    "                print(f\"   Model response: {chunk.text}\")\n",
    "    \n",
    "    if saved_files:\n",
    "        return f\"Image(s) saved: {', '.join(saved_files)}\"\n",
    "    else:\n",
    "        return \"No images were generated\"\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ§ª TESTING IMAGE GENERATION FUNCTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test 1: Generate initial image\n",
    "print(\"\\nðŸ“¸ Test 1: Generating initial image (no references)...\")\n",
    "test_prompt_1 = \"\"\"\n",
    "A cute robot character standing in a field of flowers.\n",
    "The robot has a round body, large expressive eyes, and is painted in bright blue and yellow colors.\n",
    "Style: Pixar-style 3D animation, vibrant colors, soft lighting.\n",
    "\"\"\"\n",
    "\n",
    "result_1 = generate_image_test(\n",
    "    prompt=test_prompt_1,\n",
    "    filename=\"test_robot_original\",\n",
    "    system_instruction=\"Pixar-style 3D animation\"\n",
    ")\n",
    "\n",
    "print(f\"Result 1: {result_1}\")\n",
    "\n",
    "# Extract the file path from result\n",
    "if \"saved\" in result_1.lower() and \": \" in result_1:\n",
    "    original_image_path = result_1.split(\": \")[1].strip()\n",
    "    print(f\"âœ… Original image saved at: {original_image_path}\")\n",
    "    \n",
    "    # Convert to base64 for reference\n",
    "    print(\"\\nðŸ”„ Converting image to base64 for reference...\")\n",
    "    original_base64 = image_to_base64(original_image_path)\n",
    "    print(f\"âœ… Base64 encoding complete (length: {len(original_base64)} chars)\")\n",
    "    \n",
    "    # Test 2: Generate variant using the original as reference\n",
    "    print(\"\\nðŸ“¸ Test 2: Generating variant with reference image...\")\n",
    "    test_prompt_2 = \"\"\"\n",
    "Make this robot character wave hello with one hand.\n",
    "Keep the same character design, colors, and style.\n",
    "Same background setting.\n",
    "\"\"\"\n",
    "    \n",
    "    result_2 = generate_image_test(\n",
    "        prompt=test_prompt_2,\n",
    "        filename=\"test_robot_variant\",\n",
    "        reference_images_base64=[\n",
    "            {\n",
    "                \"data\": original_base64,\n",
    "                \"mime_type\": \"image/png\"\n",
    "            }\n",
    "        ],\n",
    "        system_instruction=\"Pixar-style 3D animation\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Result 2: {result_2}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… TEST COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Check the production_assets/ folder for:\")\n",
    "    print(\"  - test_robot_original.png (original image)\")\n",
    "    print(\"  - test_robot_variant.png (variant with reference)\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"âŒ Failed to generate initial image. Check the error above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78lb2yb5y8o",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ§ª TESTING NANO BANANA PRO IMAGE GENERATION\n",
      "============================================================\n",
      "\n",
      "ðŸ“¸ Test 1: Generating initial image (no references)...\n",
      "\n",
      "ðŸŽ¨ [Generating Image with Nano Banana] 'test_nano_robot_original'\n",
      "   Prompt: \n",
      "A cute robot character standing in a field of flowers.\n",
      "The robot has a round body, large expressive...\n",
      "   System Instruction: Pixar-style 3D animation\n",
      "   ðŸ“¤ Creating task...\n",
      "   âœ… Task created: 3c0230e417bea67be69286e87494b637\n",
      "   â³ Waiting for results...\n",
      "   â³ Waiting... (attempt 1/60)\n",
      "   â³ Waiting... (attempt 2/60)\n",
      "   â³ Waiting... (attempt 3/60)\n",
      "   â³ Waiting... (attempt 4/60)\n",
      "   â³ Waiting... (attempt 5/60)\n",
      "   â³ Waiting... (attempt 6/60)\n",
      "   â³ Waiting... (attempt 7/60)\n",
      "   â³ Waiting... (attempt 8/60)\n",
      "   â³ Waiting... (attempt 9/60)\n",
      "   â³ Waiting... (attempt 10/60)\n",
      "   â³ Waiting... (attempt 11/60)\n",
      "   â³ Waiting... (attempt 12/60)\n",
      "   â³ Waiting... (attempt 13/60)\n",
      "   â³ Waiting... (attempt 14/60)\n",
      "   â³ Waiting... (attempt 15/60)\n",
      "   â³ Waiting... (attempt 16/60)\n",
      "   â³ Waiting... (attempt 17/60)\n",
      "   â³ Waiting... (attempt 18/60)\n",
      "   â³ Waiting... (attempt 19/60)\n",
      "   â³ Waiting... (attempt 20/60)\n",
      "   â³ Waiting... (attempt 21/60)\n",
      "   â³ Waiting... (attempt 22/60)\n",
      "   â³ Waiting... (attempt 23/60)\n",
      "   â³ Waiting... (attempt 24/60)\n",
      "   â³ Waiting... (attempt 25/60)\n",
      "   â³ Waiting... (attempt 26/60)\n",
      "   â³ Waiting... (attempt 27/60)\n",
      "   â³ Waiting... (attempt 28/60)\n",
      "   â³ Waiting... (attempt 29/60)\n",
      "   â³ Waiting... (attempt 30/60)\n",
      "   â³ Waiting... (attempt 31/60)\n",
      "   â³ Waiting... (attempt 32/60)\n",
      "   â³ Waiting... (attempt 33/60)\n",
      "   â³ Waiting... (attempt 34/60)\n",
      "   â³ Waiting... (attempt 35/60)\n",
      "   â³ Waiting... (attempt 36/60)\n",
      "   â³ Waiting... (attempt 37/60)\n",
      "   â³ Waiting... (attempt 38/60)\n",
      "   â³ Waiting... (attempt 39/60)\n",
      "   â³ Waiting... (attempt 40/60)\n",
      "   â³ Waiting... (attempt 41/60)\n",
      "   â³ Waiting... (attempt 42/60)\n",
      "   â³ Waiting... (attempt 43/60)\n",
      "   â³ Waiting... (attempt 44/60)\n",
      "   â³ Waiting... (attempt 45/60)\n",
      "   â³ Waiting... (attempt 46/60)\n",
      "   â³ Waiting... (attempt 47/60)\n",
      "   â³ Waiting... (attempt 48/60)\n",
      "   â³ Waiting... (attempt 49/60)\n",
      "   â³ Waiting... (attempt 50/60)\n",
      "   â³ Waiting... (attempt 51/60)\n",
      "   â³ Waiting... (attempt 52/60)\n",
      "   â³ Waiting... (attempt 53/60)\n",
      "   â³ Waiting... (attempt 54/60)\n",
      "   â³ Waiting... (attempt 55/60)\n",
      "   â³ Waiting... (attempt 56/60)\n",
      "   â³ Waiting... (attempt 57/60)\n",
      "   â³ Waiting... (attempt 58/60)\n",
      "   â³ Waiting... (attempt 59/60)\n",
      "   â³ Waiting... (attempt 60/60)\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Task timeout after 120 seconds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 17\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ“¸ Test 1: Generating initial image (no references)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m test_prompt_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124mA cute robot character standing in a field of flowers.\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124mThe robot has a round body, large expressive eyes, and is painted in bright blue and yellow colors.\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124mStyle: Pixar-style 3D animation, vibrant colors, soft lighting.\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m result_1 \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_image_nano\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_prompt_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_nano_robot_original\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43maspect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1:1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1K\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem_instruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPixar-style 3D animation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mâœ… Result 1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult_1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Extract the file path from result\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 156\u001b[0m, in \u001b[0;36mgenerate_image_nano\u001b[0;34m(prompt, filename, reference_images_base64, aspect_ratio, resolution, output_format, system_instruction)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# Query results\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   â³ Waiting for results...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 156\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mquery_nano_banana_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Download and save images\u001b[39;00m\n\u001b[1;32m    159\u001b[0m save_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduction_assets\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[18], line 100\u001b[0m, in \u001b[0;36mquery_nano_banana_task\u001b[0;34m(task_id, max_retries, retry_interval)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown state: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask timeout after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mretry_interval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Task timeout after 120 seconds"
     ]
    }
   ],
   "source": [
    "# %% [TEST] Test Nano Banana Pro Image Generation\n",
    "# Test 1: Generate an initial image without references\n",
    "# Test 2: Use that image as reference to generate a variant\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ§ª TESTING NANO BANANA PRO IMAGE GENERATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test 1: Generate initial image\n",
    "print(\"\\nðŸ“¸ Test 1: Generating initial image (no references)...\")\n",
    "test_prompt_1 = \"\"\"\n",
    "A cute robot character standing in a field of flowers.\n",
    "The robot has a round body, large expressive eyes, and is painted in bright blue and yellow colors.\n",
    "Style: Pixar-style 3D animation, vibrant colors, soft lighting.\n",
    "\"\"\"\n",
    "\n",
    "result_1 = generate_image_nano(\n",
    "    prompt=test_prompt_1,\n",
    "    filename=\"test_nano_robot_original\",\n",
    "    aspect_ratio=\"1:1\",\n",
    "    resolution=\"1K\",\n",
    "    output_format=\"png\",\n",
    "    system_instruction=\"Pixar-style 3D animation\"\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Result 1: {result_1}\")\n",
    "\n",
    "# Extract the file path from result\n",
    "if \"saved\" in result_1.lower() and \": \" in result_1:\n",
    "    original_image_path = result_1.split(\": \")[1].strip()\n",
    "    print(f\"âœ… Original image saved at: {original_image_path}\")\n",
    "    \n",
    "    # Convert to base64 for reference\n",
    "    print(\"\\nðŸ”„ Converting image to base64 for reference...\")\n",
    "    original_base64 = image_to_base64(original_image_path)\n",
    "    print(f\"âœ… Base64 encoding complete (length: {len(original_base64)} chars)\")\n",
    "    \n",
    "    # Test 2: Generate variant using the original as reference\n",
    "    print(\"\\nðŸ“¸ Test 2: Generating variant with reference image...\")\n",
    "    test_prompt_2 = \"\"\"\n",
    "Make this robot character wave hello with one hand.\n",
    "Keep the same character design, colors, and style.\n",
    "Same background setting.\n",
    "\"\"\"\n",
    "    \n",
    "    result_2 = generate_image_nano(\n",
    "        prompt=test_prompt_2,\n",
    "        filename=\"test_nano_robot_variant\",\n",
    "        reference_images_base64=[\n",
    "            {\n",
    "                \"data\": original_base64,\n",
    "                \"mime_type\": \"image/png\"\n",
    "            }\n",
    "        ],\n",
    "        aspect_ratio=\"1:1\",\n",
    "        resolution=\"1K\",\n",
    "        output_format=\"png\",\n",
    "        system_instruction=\"Pixar-style 3D animation\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ… Result 2: {result_2}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… NANO BANANA TEST COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Check the production_assets/ folder for:\")\n",
    "    print(\"  - test_nano_robot_original.png (original image)\")\n",
    "    print(\"  - test_nano_robot_variant.png (variant with reference)\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"âŒ Failed to generate initial image. Check the error above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65ee4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"action\": \"generate_image\",\n",
      "  \"action_input\": \"A professional architectural blueprint sheet in a 16\n",
      ":9 aspect ratio. The image displays a technical orthographic projection of a contemporary two-story residence with a flat roof. The layout\n",
      " is organized into three distinct technical drawings: 1) A detailed 'Floor Plan' on the left showing walls, door\n",
      " swings, a large living area, and furniture layout. 2) A 'Front Elevation' on the top right showing\n",
      " the exterior facade with geometric lines, large windows, and material textures. 3) A 'Section Cut' on the\n",
      " bottom right revealing the interior vertical structure, floor thicknesses, a staircase, and foundation details. The aesthetic is a classic blueprint\n",
      " style with crisp white technical lines, dimension markers, and annotations set against a deep blue grid background.\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To run this code you need to install the following dependencies:\n",
    "# pip install google-genai\n",
    "\n",
    "import base64\n",
    "import mimetypes\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "def save_binary_file(file_name, data):\n",
    "    f = open(file_name, \"wb\")\n",
    "    f.write(data)\n",
    "    f.close()\n",
    "    print(f\"File saved to to: {file_name}\")\n",
    "\n",
    "\n",
    "def generate():\n",
    "    client = genai.Client(\n",
    "        api_key=os.environ.get(\"GEMINI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    model = \"gemini-3-pro-preview\"\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part.from_text(text=\"\"\"Create an orthographic blueprint that describes this building in plan, elevation and section. Format 16:9.\"\"\"),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        response_modalities=[\n",
    "            \"IMAGE\",\n",
    "            \"TEXT\",\n",
    "        ],\n",
    "        system_instruction=[\n",
    "            types.Part.from_text(text=\"\"\"f\"\"\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    file_index = 0\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=generate_content_config,\n",
    "    ):\n",
    "        if (\n",
    "            chunk.candidates is None\n",
    "            or chunk.candidates[0].content is None\n",
    "            or chunk.candidates[0].content.parts is None\n",
    "        ):\n",
    "            continue\n",
    "        if chunk.candidates[0].content.parts[0].inline_data and chunk.candidates[0].content.parts[0].inline_data.data:\n",
    "            file_name = f\"ENTER_FILE_NAME_{file_index}\"\n",
    "            file_index += 1\n",
    "            inline_data = chunk.candidates[0].content.parts[0].inline_data\n",
    "            data_buffer = inline_data.data\n",
    "            file_extension = mimetypes.guess_extension(inline_data.mime_type)\n",
    "            save_binary_file(f\"{file_name}{file_extension}\", data_buffer)\n",
    "        else:\n",
    "            print(chunk.text)\n",
    "\n",
    "\n",
    "generate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c3093",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIStatusError",
     "evalue": "Error code: 405",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIStatusError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mProvider metadata:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(result\u001b[38;5;241m.\u001b[39mprovider_metadata, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m---> 75\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 29\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Note: LangChain doesn't natively support image generation endpoints\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# We'll use OpenAI client directly for image generation\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# But you can wrap it in a LangChain tool if needed\u001b[39;00m\n\u001b[1;32m     24\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAIClient(\n\u001b[1;32m     25\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m     26\u001b[0m     base_url\u001b[38;5;241m=\u001b[39mbase_url,\n\u001b[1;32m     27\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoogle/gemini-3-pro-image\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA red fox walking through a snowy forest clearing \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwith pine trees in the background\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb64_json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproviderOptions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoogleVertex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maspectRatio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1:1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafetyFilterLevel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblock_some\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result\u001b[38;5;241m.\u001b[39mdata) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo image data received from OpenAI-compatible endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/openai/resources/images.py:882\u001b[0m, in \u001b[0;36mImages.generate\u001b[0;34m(self, prompt, background, model, moderation, n, output_compression, output_format, partial_images, quality, response_format, size, stream, style, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate\u001b[39m(\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    880\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m not_given,\n\u001b[1;32m    881\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ImagesResponse \u001b[38;5;241m|\u001b[39m Stream[ImageGenStreamEvent]:\n\u001b[0;32m--> 882\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/images/generations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackground\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmoderation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmoderation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_compression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpartial_images\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquality\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstyle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimage_generate_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageGenerateParamsStreaming\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_generate_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageGenerateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mImagesResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mImageGenStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Proj/master-clash/.venv/lib/python3.12/site-packages/openai/_base_client.py:1047\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1046\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1047\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAPIStatusError\u001b[0m: Error code: 405"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from openai import OpenAI as OpenAIClient\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def main():\n",
    "    api_key = os.getenv(\"AI_GATEWAY_API_KEY\") or os.getenv(\"VERCEL_OIDC_TOKEN\") or \"vck_1cXg3aB18kewl7egHKcpLCVICAiVSaPoQvsV6RqjhQjMgk2rVR4BW0bu\"\n",
    "    base_url = (\n",
    "        os.getenv(\"AI_GATEWAY_BASE_OPENAI_COMPAT_URL\")\n",
    "        or \"https://ai-gateway.vercel.sh/v1\"\n",
    "    )\n",
    "\n",
    "    # Note: LangChain doesn't natively support image generation endpoints\n",
    "    # We'll use OpenAI client directly for image generation\n",
    "    # But you can wrap it in a LangChain tool if needed\n",
    "    \n",
    "    client = OpenAIClient(\n",
    "        api_key=api_key,\n",
    "        base_url=base_url,\n",
    "    )\n",
    "\n",
    "    result = client.images.generate(\n",
    "        model=\"google/gemini-3-pro-image\",\n",
    "        prompt=(\n",
    "            \"A red fox walking through a snowy forest clearing \"\n",
    "            \"with pine trees in the background\"\n",
    "        ),\n",
    "        n=2,\n",
    "        response_format=\"b64_json\",\n",
    "        extra_body={\n",
    "            \"providerOptions\": {\n",
    "                \"googleVertex\": {\n",
    "                    \"aspectRatio\": \"1:1\",\n",
    "                    \"safetyFilterLevel\": \"block_some\",\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    if not result or not result.data or len(result.data) == 0:\n",
    "        raise Exception(\"No image data received from OpenAI-compatible endpoint\")\n",
    "\n",
    "    print(f\"Generated {len(result.data)} image(s)\")\n",
    "\n",
    "    for i, image in enumerate(result.data):\n",
    "        if hasattr(image, \"b64_json\") and image.b64_json:\n",
    "            # Decode base64 to get image size\n",
    "            image_bytes = base64.b64decode(image.b64_json)\n",
    "            print(f\"Image {i+1}:\")\n",
    "            print(f\"  Size: {len(image_bytes)} bytes\")\n",
    "            print(f\"  Base64 preview: {image.b64_json[:50]}...\")\n",
    "\n",
    "            # Save image to file with timestamp\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_file = f\"output/output_image_{timestamp}_{i+1}.png\"\n",
    "            print(f\"  Saving image to {output_file}\")\n",
    "            \n",
    "            # Create output directory if it doesn't exist\n",
    "            os.makedirs(\"output\", exist_ok=True)\n",
    "            \n",
    "            with open(output_file, \"wb\") as f:\n",
    "                f.write(image_bytes)\n",
    "\n",
    "    if hasattr(result, \"provider_metadata\"):\n",
    "        print(\"\\nProvider metadata:\")\n",
    "        print(json.dumps(result.provider_metadata, indent=2))\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-clash (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
