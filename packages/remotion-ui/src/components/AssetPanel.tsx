import React, { useRef } from 'react';
import { useEditor } from '@master-clash/remotion-core';
import type { Asset, TextItem } from '@master-clash/remotion-core';
import { loadAudioWaveform } from '@master-clash/remotion-core';

// Export for TimelineTracksContainer to use
export let currentDraggedAsset: any = null;
export let currentAssetDragOffset: number = 0; // é¼ æ ‡ç›¸å¯¹äº asset å¡ç‰‡å·¦è¾¹ç¼˜çš„åç§»é‡ï¼ˆåƒç´ ï¼‰

export const AssetPanel: React.FC = () => {
  const { state, dispatch } = useEditor();
  const fileInputRef = useRef<HTMLInputElement>(null);

  const generateVideoThumbnail = (videoUrl: string): Promise<{ thumbnail: string; frameCount: number; frameWidth: number }> => {
    return new Promise((resolve) => {
      const video = document.createElement('video');
      video.src = videoUrl;
      video.crossOrigin = 'anonymous';
      video.preload = 'metadata';

      video.addEventListener('loadedmetadata', async () => {
        try {
          // Note: video.duration reads from container metadata, which may include
          // extra audio beyond the video stream. This can cause a few frames difference
          // compared to professional tools. Users can manually adjust in the timeline.
          const duration = video.duration;

          const frameInterval = 1.0; // æ¯1ç§’æå–ä¸€å¸§
          const startTime = 0.5; // ä»0.5ç§’å¼€å§‹
          const frameCount = Math.min(Math.floor((duration - startTime) / frameInterval) + 1, 100); // æœ€å¤š100å¸§

          const originalFrameWidth = video.videoWidth;
          const originalFrameHeight = video.videoHeight;

          // è®¾ç½®æ¯ä¸€å¸§çš„ç›®æ ‡å®½åº¦ï¼ˆæ¨ªå‘è£å‰ª/ç¼©æ”¾ï¼‰
          const targetFrameHeight = 80; // å›ºå®šé«˜åº¦
          const targetFrameWidth = Math.floor((originalFrameWidth / originalFrameHeight) * targetFrameHeight);

          // åˆ›å»ºä¸€ä¸ªå®½ç”»å¸ƒæ¥å®¹çº³æ‰€æœ‰å¸§
          const canvas = document.createElement('canvas');
          canvas.width = targetFrameWidth * frameCount;
          canvas.height = targetFrameHeight;
          const ctx = canvas.getContext('2d');

          if (!ctx) {
            resolve({ thumbnail: videoUrl, frameCount: 1, frameWidth: 1 });
            return;
          }

          // æå–æ¯ä¸€å¸§
          for (let i = 0; i < frameCount; i++) {
            const time = startTime + i * frameInterval;

            // ç­‰å¾…è§†é¢‘è·³è½¬åˆ°æŒ‡å®šæ—¶é—´
            await new Promise<void>((resolveSeek) => {
              const seeked = () => {
                video.removeEventListener('seeked', seeked);
                resolveSeek();
              };
              video.addEventListener('seeked', seeked);
              video.currentTime = Math.min(time, duration - 0.1);
            });

            // å°†å½“å‰å¸§ç¼©æ”¾å¹¶ç»˜åˆ¶åˆ°ç”»å¸ƒä¸Š
            ctx.drawImage(
              video,
              0, 0, originalFrameWidth, originalFrameHeight, // æºåŒºåŸŸ
              i * targetFrameWidth, 0, targetFrameWidth, targetFrameHeight // ç›®æ ‡åŒºåŸŸ
            );
          }

          // å°†ç”»å¸ƒè½¬æ¢ä¸ºblob
          canvas.toBlob((blob) => {
            if (blob) {
              resolve({
                thumbnail: URL.createObjectURL(blob),
                frameCount,
                frameWidth: targetFrameWidth
              });
            } else {
              resolve({ thumbnail: videoUrl, frameCount: 1, frameWidth: 1 });
            }
          }, 'image/jpeg', 0.75);
        } catch (err) {
          console.error('Error generating thumbnail:', err);
          resolve({ thumbnail: videoUrl, frameCount: 1, frameWidth: 1 });
        }
      });

      video.addEventListener('error', () => {
        resolve({ thumbnail: videoUrl, frameCount: 1, frameWidth: 1 }); // fallback on error
      });
    });
  };

  const handleFileUpload = async (e: React.ChangeEvent<HTMLInputElement>) => {
    const files = e.target.files;
    if (!files) return;

    for (const file of Array.from(files)) {
      const url = URL.createObjectURL(file);
      const type = file.type.startsWith('video')
        ? 'video'
        : file.type.startsWith('audio')
          ? 'audio'
          : 'image';

      let thumbnail: string | undefined;
      let thumbnailFrameCount: number | undefined;
      let thumbnailFrameWidth: number | undefined;
      let waveform: number[] | undefined;
      let duration: number | undefined;

      // Get duration for video/audio
      if (type === 'video' || type === 'audio') {
        try {
          duration = await new Promise<number>((resolve, reject) => {
            const media = document.createElement(type === 'video' ? 'video' : 'audio');
            media.src = url;
            media.addEventListener('loadedmetadata', () => {
              resolve(media.duration);
            });
            media.addEventListener('error', reject);
          });
        } catch (error) {
          console.error('Error getting duration:', error);
        }
      }

      // Generate thumbnail for video
      if (type === 'video') {
        const result = await generateVideoThumbnail(url);
        thumbnail = result.thumbnail;
        thumbnailFrameCount = result.frameCount;
        thumbnailFrameWidth = result.frameWidth;
      }

      // Generate waveform for audio and video
      if (type === 'audio' || type === 'video') {
        try {
          waveform = await loadAudioWaveform(url, 500); // Increased from 100 to 500 for finer granularity
        } catch (error) {
          console.error('Error generating waveform:', error);
        }
      }

      const asset: Asset = {
        id: `asset-${Date.now()}-${Math.random()}`,
        name: file.name,
        type: type as 'video' | 'audio' | 'image',
        src: url,
        duration,
        thumbnail,
        thumbnailFrameCount,
        thumbnailFrameWidth,
        waveform,
        createdAt: Date.now(),
      };

      dispatch({ type: 'ADD_ASSET', payload: asset });
    }

    if (fileInputRef.current) {
      fileInputRef.current.value = '';
    }
  };

  const handleAssetDragStart = (e: React.DragEvent, asset: Asset) => {
    currentDraggedAsset = asset; // Store globally

    // è®¡ç®—é¼ æ ‡ç›¸å¯¹äº asset å¡ç‰‡å·¦è¾¹ç¼˜çš„åç§»é‡
    const target = e.currentTarget as HTMLElement;
    const rect = target.getBoundingClientRect();
    currentAssetDragOffset = e.clientX - rect.left;

    e.dataTransfer.effectAllowed = 'copy';
    e.dataTransfer.setData('text/plain', asset.id); // Use text/plain for better compatibility
    e.dataTransfer.setData('assetId', asset.id);
    e.dataTransfer.setData('asset', JSON.stringify(asset));
  };

  const handleAddTextToTrack = () => {
    const newItemDuration = 90; // 3 seconds at 30fps
    const newItemFrom = state.currentFrame;
    const newItemTo = newItemFrom + newItemDuration;

    // æ£€æµ‹ç¬¬ä¸€è½¨é“æ˜¯å¦æœ‰é‡å 
    let trackId: string;
    let needsNewTrack = false;

    if (state.tracks.length === 0) {
      // æ²¡æœ‰è½¨é“ï¼Œåˆ›å»ºæ–°è½¨é“
      trackId = `track-${Date.now()}`;
      needsNewTrack = true;
    } else {
      const firstTrack = state.tracks[0];
      // æ£€æŸ¥ç¬¬ä¸€è½¨é“ä¸Šæ˜¯å¦æœ‰å…ƒç´ ä¸æ–°å…ƒç´ æ—¶é—´èŒƒå›´é‡å 
      const hasOverlap = firstTrack.items.some(item => {
        const itemFrom = item.from;
        const itemTo = item.from + item.durationInFrames;
        // ä¸¤ä¸ªæ—¶é—´èŒƒå›´é‡å çš„æ¡ä»¶ï¼šnewItemFrom < itemTo && newItemTo > itemFrom
        return newItemFrom < itemTo && newItemTo > itemFrom;
      });

      if (hasOverlap) {
        // æœ‰é‡å ï¼Œåˆ›å»ºæ–°è½¨é“å¹¶æ’å…¥åˆ°ç¬¬ä¸€ä½ç½®
        trackId = `track-${Date.now()}`;
        needsNewTrack = true;
      } else {
        // æ— é‡å ï¼Œä½¿ç”¨ç¬¬ä¸€è½¨é“
        trackId = firstTrack.id;
      }
    }

    // å¦‚æœéœ€è¦æ–°è½¨é“ï¼Œå…ˆåˆ›å»º
    if (needsNewTrack) {
      dispatch({
        type: 'INSERT_TRACK',
        payload: {
          track: {
            id: trackId,
            name: 'Text',
            items: [],
          },
          index: 0, // æ’å…¥åˆ°ç¬¬ä¸€ä½ç½®
        }
      });
    }

    // åˆ›å»º text item
    const textItem: TextItem = {
      id: `text-${Date.now()}`,
      type: 'text',
      text: 'Double click to edit',
      color: '#ffffff',
      from: newItemFrom,
      durationInFrames: newItemDuration,
      fontSize: 60,
      properties: {
        x: 0,
        y: 0,
        width: 1,
        height: 1,
        rotation: 0,
        opacity: 1,
      },
    };

    // ä½¿ç”¨ setTimeout ç¡®ä¿è½¨é“å…ˆåˆ›å»º
    setTimeout(() => {
      dispatch({
        type: 'ADD_ITEM',
        payload: { trackId, item: textItem },
      });
    }, 0);
  };

  // Handle dragging Quick Add items
  const handleQuickAddDragStart = (e: React.DragEvent, type: 'text' | 'solid') => {
    // Create a pseudo-asset for quick add items
    const pseudoAsset = {
      id: `quick-${type}-${Date.now()}`,
      name: type === 'text' ? 'Text' : 'Color',
      type: type as 'text' | 'solid',
      src: '',
      createdAt: Date.now(),
    };

    currentDraggedAsset = { ...pseudoAsset, quickAdd: true, quickAddType: type }; // Store globally

    // è®¡ç®—é¼ æ ‡ç›¸å¯¹äºæŒ‰é’®å·¦è¾¹ç¼˜çš„åç§»é‡
    const target = e.currentTarget as HTMLElement;
    const rect = target.getBoundingClientRect();
    currentAssetDragOffset = e.clientX - rect.left;

    e.dataTransfer.effectAllowed = 'copy';
    e.dataTransfer.setData('text/plain', pseudoAsset.id); // Use text/plain for compatibility
    e.dataTransfer.setData('assetId', pseudoAsset.id);
    e.dataTransfer.setData('quickAdd', 'true');
    e.dataTransfer.setData('quickAddType', type);
  };

  return (

    <div className="flex flex-col h-full bg-slate-50">
      <div className="px-4 py-3 bg-white border-b border-slate-200">
        <h2 className="m-0 text-sm font-bold text-slate-900">Assets</h2>
      </div>

      <div className="flex-1 overflow-auto p-4">
        {/* Quick Add Section */}
        <div className="mb-6">
          <h3 className="m-0 mb-3 text-xs font-bold text-slate-500 uppercase tracking-wider">Quick Add</h3>
          <div className="flex gap-2">
            <button
              onClick={handleAddTextToTrack}
              className="flex-1 py-2 px-3 bg-white text-slate-700 border border-slate-200 rounded-lg text-sm font-medium hover:border-blue-400 hover:text-blue-600 hover:bg-blue-50 transition-all cursor-grab active:cursor-grabbing shadow-sm"
              draggable
              onDragStart={(e) => handleQuickAddDragStart(e, 'text')}
              title="Click to add or drag to timeline"
            >
              + Text
            </button>
            <button
              onClick={() => {
                const newItemDuration = 30; // 1 second at 30fps (smaller initial size)
                const newItemFrom = state.currentFrame;
                const newItemTo = newItemFrom + newItemDuration;

                // æ£€æµ‹ç¬¬ä¸€è½¨é“æ˜¯å¦æœ‰é‡å 
                let trackId: string;
                let needsNewTrack = false;

                if (state.tracks.length === 0) {
                  // æ²¡æœ‰è½¨é“ï¼Œåˆ›å»ºæ–°è½¨é“
                  trackId = `track-${Date.now()}`;
                  needsNewTrack = true;
                } else {
                  const firstTrack = state.tracks[0];
                  // æ£€æŸ¥ç¬¬ä¸€è½¨é“ä¸Šæ˜¯å¦æœ‰å…ƒç´ ä¸æ–°å…ƒç´ æ—¶é—´èŒƒå›´é‡å 
                  const hasOverlap = firstTrack.items.some(item => {
                    const itemFrom = item.from;
                    const itemTo = item.from + item.durationInFrames;
                    // ä¸¤ä¸ªæ—¶é—´èŒƒå›´é‡å çš„æ¡ä»¶ï¼šnewItemFrom < itemTo && newItemTo > itemFrom
                    return newItemFrom < itemTo && newItemTo > itemFrom;
                  });

                  if (hasOverlap) {
                    // æœ‰é‡å ï¼Œåˆ›å»ºæ–°è½¨é“å¹¶æ’å…¥åˆ°ç¬¬ä¸€ä½ç½®
                    trackId = `track-${Date.now()}`;
                    needsNewTrack = true;
                  } else {
                    // æ— é‡å ï¼Œä½¿ç”¨ç¬¬ä¸€è½¨é“
                    trackId = firstTrack.id;
                  }
                }

                // å¦‚æœéœ€è¦æ–°è½¨é“ï¼Œå…ˆåˆ›å»º
                if (needsNewTrack) {
                  dispatch({
                    type: 'INSERT_TRACK',
                    payload: {
                      track: {
                        id: trackId,
                        name: 'Solid',
                        items: [],
                      },
                      index: 0, // æ’å…¥åˆ°ç¬¬ä¸€ä½ç½®
                    }
                  });
                }

                // åˆ›å»º solid item
                const solidItem = {
                  id: `solid-${Date.now()}`,
                  type: 'solid' as const,
                  color: '#' + Math.floor(Math.random() * 16777215).toString(16),
                  from: newItemFrom,
                  durationInFrames: newItemDuration,
                  properties: {
                    x: 0,
                    y: 0,
                    width: 1,
                    height: 1,
                    rotation: 0,
                    opacity: 1,
                  },
                };

                // ä½¿ç”¨ setTimeout ç¡®ä¿è½¨é“å…ˆåˆ›å»º
                setTimeout(() => {
                  dispatch({
                    type: 'ADD_ITEM',
                    payload: {
                      trackId,
                      item: solidItem,
                    },
                  });
                }, 0);
              }}
              className="flex-1 py-2 px-3 bg-white text-slate-700 border border-slate-200 rounded-lg text-sm font-medium hover:border-blue-400 hover:text-blue-600 hover:bg-blue-50 transition-all cursor-grab active:cursor-grabbing shadow-sm"
              draggable
              onDragStart={(e) => handleQuickAddDragStart(e, 'solid')}
              title="Click to add or drag to timeline"
            >
              + Color
            </button>
          </div>
        </div>

        {/* Upload Section */}
        <div className="mb-6">
          <h3 className="m-0 mb-3 text-xs font-bold text-slate-500 uppercase tracking-wider">Media Files</h3>
          <input
            ref={fileInputRef}
            type="file"
            accept="image/*,video/*,audio/*"
            multiple
            className="hidden"
            onChange={handleFileUpload}
          />
          <button
            onClick={() => fileInputRef.current?.click()}
            className="w-full py-3 px-4 bg-blue-600 text-white rounded-lg text-sm font-semibold hover:bg-blue-700 transition-colors shadow-sm hover:shadow active:scale-95"
          >
            Upload Files
          </button>
        </div>

        {/* Assets List */}
        <div className="flex flex-col gap-2">
          {state.assets.length === 0 ? (
            <div className="text-center py-8 text-slate-400 text-sm bg-slate-100/50 rounded-lg border border-dashed border-slate-200">
              No assets uploaded yet
            </div>
          ) : (
            state.assets.map((asset) => (
              <div
                key={asset.id}
                draggable
                onDragStart={(e) => handleAssetDragStart(e, asset)}
                className="group flex items-center p-2 bg-white border border-slate-200 rounded-lg cursor-move hover:border-blue-400 hover:shadow-sm transition-all gap-3"
              >
                {asset.type === 'image' && (
                  <img
                    src={asset.src}
                    alt={asset.name}
                    className="w-12 h-12 object-cover object-left-top rounded bg-slate-100 border border-slate-100"
                  />
                )}
                {asset.type === 'video' && (
                  <img
                    src={asset.thumbnail || asset.src}
                    alt={asset.name}
                    className="w-12 h-12 object-cover object-left-top rounded bg-slate-100 border border-slate-100"
                  />
                )}
                {asset.type === 'audio' && (
                  <div className="w-12 h-12 flex items-center justify-center bg-slate-100 rounded text-xl border border-slate-200">ğŸµ</div>
                )}
                <div className="flex-1 min-w-0">
                  <div className="text-sm font-medium text-slate-900 truncate">{asset.name}</div>
                  <div className="text-xs text-slate-500 capitalize mt-0.5">{asset.type}</div>
                </div>
                {!asset.readOnly && (
                  <button
                    onClick={() => dispatch({ type: 'REMOVE_ASSET', payload: asset.id })}
                    className="w-6 h-6 flex items-center justify-center text-slate-400 hover:text-red-500 hover:bg-red-50 rounded transition-colors opacity-0 group-hover:opacity-100"
                  >
                    Ã—
                  </button>
                )}
              </div>
            ))
          )}
        </div>
      </div>
    </div>
  );
};
